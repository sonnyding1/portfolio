[
  {
    "id": "japanese-conversation-bot",
    "title": "Japanese Conversation Bot",
    "technologies": "Django, JavaScript, Docker",
    "featured": true,
    "og": "/japanese-conversation-bot.png",
    "body": "This is a project that I worked on when OpenAI API first became publicly available. The aim of the project is to have a Japanese tutor who can converse with the user in Japanese, correct the user's errors, and encourage the user to become more proficient in speaking Japanese as they converse with the chatbot.\r\n\r\n## Overview\r\n\r\nThe ideal flow of the project is: user presses the \"speak\" button and speaks in Japanese -> Whisper transcribes text, transcribed text appears in the text area, users may manually correct any mistakes by typing -> submit user message -> user message sent to OpenAI API, the API returns a response -> response as a piece of text is displayed on the web app -> response as a piece of text is sent to VoiceVox, which performs text to speech.\r\n\r\n![](/japanese-conversation-bot/flowchart.png)\r\n\r\nThis project uses Flask and HTML, Tailwind CSS, JavaScript.\r\n\r\n## Capture User Audio\r\n\r\nA `POST` request is sent from my web app's root route to `/transcribe`. In there, I captured a blob of audio, saved it, and sent it to Whisper via `openai`, a Python wrapper of the OpenAI API.\r\n\r\n```python\r\nblob = request.files['blob'].read()\r\nwith open('blob.wav', 'wb') as f:\r\n    f.write(blob)\r\naudio_file = open('blob.wav', \"rb\")\r\nopenai.api_key = config.OPENAI_API_KEY\r\ntranscript = openai.Audio.transcribe(\"whisper-1\", audio_file)[\"text\"]\r\nreturn jsonify({'output': transcript})\r\n```\r\n\r\n## Choosing good Text to Speech API\r\n\r\nI have actually compared different TTS options available to me.\r\n\r\nSpeechCloud API was too expensive, it was priced at around 0.01 Euro per word/character. Coqui seems doable, but currently stuck with some character parsing issues. Voicevox proves to be very useful. I downloaded it locally, which also started a local at the same time. I wrote a script that performs audio query and synthesizes the query into an audio file. I was also able to parse the returned JSON from get_speakers() method to have a clearer manual on speaker selection.\r\n\r\n## VoiceVox in Docker\r\n\r\nAt the beginning, I made use of VoiceVox by actually downloading the software and opening it locally. To make it simpler for the user, I used the following code snippet to run a Docker container version of the VoiceVox server.\r\n\r\n```python\r\nimport docker\r\n\r\nclient = docker.from_env()\r\n\r\n# Pull the Docker image\r\nclient.images.pull('voicevox/voicevox_engine:cpu-ubuntu20.04-latest')\r\n\r\n# Run the Docker container\r\ncontainer = client.containers.run(\r\n    'voicevox/voicevox_engine:cpu-ubuntu20.04-latest',\r\n    detach=True,\r\n    ports={'50021/tcp': ('127.0.0.1', 50021)},\r\n    remove=True,\r\n    tty=True\r\n)\r\n\r\n# Print the container logs\r\nprint(container.logs(follow=True))\r\n```\r\n\r\nAlso, stop the Docker container that contains the VoiceVox image on exit using the atexit library.\r\n\r\n```python\r\ndef OnExitApp():\r\n    tts.stop_voicevox()\r\n\r\natexit.register(OnExitApp)\r\n```\r\n\r\n## UI\r\n\r\nThe UI looks like this:\r\n\r\n![](/japanese-conversation-bot.png)\r\n\r\nBefore that, I have also made a prototype using Gradio.\r\n\r\n![](/japanese-conversation-bot/gradio.png)\r\n\r\n## Closing Notes\r\n\r\nGoing further, I may be able to improve the UI, incorporate more features such as displaying Furigana, bookmarking good conversations, and so on. Overall, it was very fun working on this project. I got to practice a lot about how to leverage existing solutions to build something that I wish existed."
  },
  {
    "id": "chatgpt-cli",
    "title": "ChatGPT cli",
    "technologies": "Python",
    "featured": false,
    "og": "/PixPin_2024-03-27_13-30-35.png",
    "body": "\r\nRecently, OpenAI released API for ChatGPT, I took advantage of that, and did a little test run. This is going to be a fairly short blog post, all I've done is to test the new API.\r\n\r\n## API\r\n\r\nAccording to [OpenAI's API](https://platform.openai.com/docs/guides/chat/introduction), a call for a ChatGPT response using Python is in the following format:\r\n\r\n```python\r\nimport openai\r\n\r\nopenai.ChatCompletion.create(\r\n  model=\"gpt-3.5-turbo\",\r\n  messages=[\r\n        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\r\n        {\"role\": \"user\", \"content\": \"Who won the world series in 2020?\"},\r\n        {\"role\": \"assistant\", \"content\": \"The Los Angeles Dodgers won the World Series in 2020.\"},\r\n        {\"role\": \"user\", \"content\": \"Where was it played?\"}\r\n    ]\r\n)\r\n```\r\n\r\nHere, `gpt-3.5-turbo` is ChatGPT. `messages` stores the whole conversation, including the initial prompt in the role of `system`, user's questions in the role of `user`, and ChatGPT's response in the role of `assistant`. The `create` function returns a response like this:\r\n\r\n```txt\r\n{\r\n 'id': 'chatcmpl-6p9XYPYSTTRi0xEviKjjilqrWU2Ve',\r\n 'object': 'chat.completion',\r\n 'created': 1677649420,\r\n 'model': 'gpt-3.5-turbo',\r\n 'usage': {'prompt_tokens': 56, 'completion_tokens': 31, 'total_tokens': 87},\r\n 'choices': [\r\n   {\r\n    'message': {\r\n      'role': 'assistant',\r\n      'content': 'The 2020 World Series was played in Arlington, Texas at the Globe Life Field, which was the new home stadium for the Texas Rangers.'},\r\n    'finish_reason': 'stop',\r\n    'index': 0\r\n   }\r\n  ]\r\n}\r\n```\r\n\r\nWhich, we really only care about the content most of the time.\r\n\r\n## Implementation\r\n\r\nFirst of all, I get my OpenAI API key. Then, I simply wrote a while loop, at the beginning of each iteration it asks for a user input. If user types !Q, then the program quits. If user types !SAVE, program saves this session's entire conversation for record or for future use. I have both raw version and formatted version.\r\n\r\n```python\r\nwhile True:\r\n    user_input = input(user_header)\r\n    # exit condition\r\n    if user_input == \"!Q\":\r\n        return\r\n    # promp save\r\n    if user_input == \"!SAVE\":\r\n        parsed_messages = []\r\n        for i in messages:\r\n            parsed_messages.append(f\"{i['role']}: {i['content']}\\n\")\r\n\r\n        now = datetime.datetime.now()\r\n        timestamp = now.strftime(\"%Y-%m-%d-%H-%M-%S\")\r\n        try:\r\n            # save raw messages\r\n            with open(file=f'C:\\code\\chatGPT\\log\\{timestamp}.txt', mode='w', encoding='utf-8') as f:\r\n                f.write(str(messages))\r\n            #save formatted messages\r\n            with open(file=f'C:\\code\\chatGPT\\log\\\\f-{timestamp}.txt', mode='w', encoding='utf-8') as f:\r\n                for i in parsed_messages:\r\n                    f.write(i)\r\n        except IOError:\r\n            print(\"Error: Could not create file.\")\r\n        print(GPT_header + 'Your file has been saved! Let me know if you need any further assistance.')\r\n        continue\r\n```\r\n\r\nNote that `split_string()` is a function I wrote solely for the purpose of readability of text. Also, `GPT_header` is a colored string achieved using `colorama`.\r\n\r\nAs for handling the `messages` part, I first initiated a list called `messages` outside of the while loop, then within the while loop, I appended both the user's prompt and ChatGPT's answer to `messages`. As for getting the responses, I followed the documentations.\r\n\r\n```python\r\nmessages.append({\"role\": \"user\", \"content\": user_input})\r\n\r\nresponse = openai.ChatCompletion.create(\r\n    model=\"gpt-3.5-turbo\",\r\n    messages=messages\r\n)\r\n\r\nprint(GPT_header + response['choices'][0]['message']['content'])\r\n\r\nmessages.append({\"role\": \"assistant\", \"content\": response['choices'][0]['message']['content']})\r\n```\r\n\r\nOh, and finally, as a cherry on top, I created a `.bat` file named `gpt.bat` under the `\\scripts` folder of Python, because this folder is included in `PATH` of my computer, and now I can simply type `gpt` in terminal to run my script.\r\n\r\n```bat\r\n@echo off\r\npython \"C:\\path\\to\\my\\script.py\" %*\r\n```\r\n\r\n## Demo\r\n\r\n![img1](https://i3.lensdump.com/i/TBTjCq.png)\r\n\r\n![img2](https://i1.lensdump.com/i/TBTWhD.png)\r\n\r\n![img3](https://i.lensdump.com/i/TBTAY0.png)\r\n\r\n## Conclusion\r\n\r\nThis project alone is pretty much useless, because with everything you can do on the cli program, you can do it on the official website. However, in the future, I might implement some more interesting programs, such as a foreign language tutor, a personal assistant, a story teller and so on.\r\n"
  },
  {
    "id": "interactive-math-web-app",
    "title": "Interative Math Web App",
    "technologies": "Next.js, React.js, MongoDB",
    "featured": true,
    "og": "/math-webapp.png",
    "body": "\r\nThis is a math web app that allows you to do math calculations in the browser. It supports basic arithmetic operations, such as addition, subtraction, multiplication, and division. You can also perform more advanced operations, such as exponentiation, square roots, and trigonometric functions.\r\n\r\n# Features\r\n\r\n- Basic arithmetic operations\r\n- Advanced math functions\r\n- Interactive graphing\r\n- Customizable settings\r\n- Save and load calculations\r\n\r\n# Technologies Used\r\n\r\n- HTML\r\n- CSS\r\n- JavaScript\r\n- Math.js\r\n- Chart.js\r\n- LocalStorage\r\n\r\n# Implementations\r\n\r\n```javascript\r\nfunction add(a, b) {\r\n  return a + b;\r\n}\r\n\r\nfunction subtract(a, b) {\r\n  return a - b;\r\n}\r\n```\r\n\r\n## h2\r\n\r\n### h3\r\n"
  }
]