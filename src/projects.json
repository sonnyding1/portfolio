[
  {
    "id": "japanese-conversation-bot",
    "title": "Japanese Conversation Bot",
    "technologies": "Django, JavaScript, Docker",
    "featured": true,
    "og": "https://na-406607901.imgix.net/japanese-conversation-bot/japanese-conversation-bot.png",
    "date": "2023-04-01T00:00:00.000Z",
    "body": "This is a project that I worked on when OpenAI API first became publicly available. The aim of the project is to have a Japanese tutor who can converse with the user in Japanese, correct the user's errors, and encourage the user to become more proficient in speaking Japanese as they converse with the chatbot.\n\n## Overview\n\nThe ideal flow of the project is: user presses the \"speak\" button and speaks in Japanese -> Whisper transcribes text, transcribed text appears in the text area, users may manually correct any mistakes by typing -> submit user message -> user message sent to OpenAI API, the API returns a response -> response as a piece of text is displayed on the web app -> response as a piece of text is sent to VoiceVox, which performs text to speech.\n\n![](https://na-406607901.imgix.net/japanese-conversation-bot/flowchart.png)\n\nThis project uses Flask and HTML, Tailwind CSS, JavaScript.\n\n## Capture User Audio\n\nA `POST` request is sent from my web app's root route to `/transcribe`. In there, I captured a blob of audio, saved it, and sent it to Whisper via `openai`, a Python wrapper of the OpenAI API.\n\n```python\nblob = request.files['blob'].read()\nwith open('blob.wav', 'wb') as f:\n    f.write(blob)\naudio_file = open('blob.wav', \"rb\")\nopenai.api_key = config.OPENAI_API_KEY\ntranscript = openai.Audio.transcribe(\"whisper-1\", audio_file)[\"text\"]\nreturn jsonify({'output': transcript})\n```\n\n## Choosing good Text to Speech API\n\nI have actually compared different TTS options available to me.\n\nSpeechCloud API was too expensive, it was priced at around 0.01 Euro per word/character. Coqui seems doable, but currently stuck with some character parsing issues. Voicevox proves to be very useful. I downloaded it locally, which also started a local at the same time. I wrote a script that performs audio query and synthesizes the query into an audio file. I was also able to parse the returned JSON from get_speakers() method to have a clearer manual on speaker selection.\n\n## VoiceVox in Docker\n\nAt the beginning, I made use of VoiceVox by actually downloading the software and opening it locally. To make it simpler for the user, I used the following code snippet to run a Docker container version of the VoiceVox server.\n\n```python\nimport docker\n\nclient = docker.from_env()\n\n# Pull the Docker image\nclient.images.pull('voicevox/voicevox_engine:cpu-ubuntu20.04-latest')\n\n# Run the Docker container\ncontainer = client.containers.run(\n    'voicevox/voicevox_engine:cpu-ubuntu20.04-latest',\n    detach=True,\n    ports={'50021/tcp': ('127.0.0.1', 50021)},\n    remove=True,\n    tty=True\n)\n\n# Print the container logs\nprint(container.logs(follow=True))\n```\n\nAlso, stop the Docker container that contains the VoiceVox image on exit using the atexit library.\n\n```python\ndef OnExitApp():\n    tts.stop_voicevox()\n\natexit.register(OnExitApp)\n```\n\n## UI\n\nThe UI looks like this:\n\n![](https://na-406607901.imgix.net/japanese-conversation-bot/japanese-conversation-bot.png)\n\nBefore that, I have also made a prototype using Gradio.\n\n![](https://na-406607901.imgix.net/japanese-conversation-bot/gradio.png)\n\n## Closing Notes\n\nGoing further, I may be able to improve the UI, incorporate more features such as displaying Furigana, bookmarking good conversations, and so on. Overall, it was very fun working on this project. I got to practice a lot about how to leverage existing solutions to build something that I wish existed.\n"
  },
  {
    "id": "chatgpt-cli",
    "title": "ChatGPT CLI",
    "technologies": "Python",
    "featured": false,
    "og": "https://na-406607901.imgix.net/chatgpt-cli/chatgpt-cli.png",
    "date": "2023-03-01T00:00:00.000Z",
    "body": "Recently, OpenAI released API for ChatGPT, I took advantage of that, and did a little test run. This is going to be a fairly short blog post, all I've done is to test the new API.\n\n## API\n\nAccording to [OpenAI's API](https://platform.openai.com/docs/guides/chat/introduction), a call for a ChatGPT response using Python is in the following format:\n\n```python\nimport openai\n\nopenai.ChatCompletion.create(\n  model=\"gpt-3.5-turbo\",\n  messages=[\n        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n        {\"role\": \"user\", \"content\": \"Who won the world series in 2020?\"},\n        {\"role\": \"assistant\", \"content\": \"The Los Angeles Dodgers won the World Series in 2020.\"},\n        {\"role\": \"user\", \"content\": \"Where was it played?\"}\n    ]\n)\n```\n\nHere, `gpt-3.5-turbo` is ChatGPT. `messages` stores the whole conversation, including the initial prompt in the role of `system`, user's questions in the role of `user`, and ChatGPT's response in the role of `assistant`. The `create` function returns a response like this:\n\n```txt\n{\n 'id': 'chatcmpl-6p9XYPYSTTRi0xEviKjjilqrWU2Ve',\n 'object': 'chat.completion',\n 'created': 1677649420,\n 'model': 'gpt-3.5-turbo',\n 'usage': {'prompt_tokens': 56, 'completion_tokens': 31, 'total_tokens': 87},\n 'choices': [\n   {\n    'message': {\n      'role': 'assistant',\n      'content': 'The 2020 World Series was played in Arlington, Texas at the Globe Life Field, which was the new home stadium for the Texas Rangers.'},\n    'finish_reason': 'stop',\n    'index': 0\n   }\n  ]\n}\n```\n\nWhich, we really only care about the content most of the time.\n\n## Implementation\n\nFirst of all, I get my OpenAI API key. Then, I simply wrote a while loop, at the beginning of each iteration it asks for a user input. If user types !Q, then the program quits. If user types !SAVE, program saves this session's entire conversation for record or for future use. I have both raw version and formatted version.\n\n```python\nwhile True:\n    user_input = input(user_header)\n    # exit condition\n    if user_input == \"!Q\":\n        return\n    # promp save\n    if user_input == \"!SAVE\":\n        parsed_messages = []\n        for i in messages:\n            parsed_messages.append(f\"{i['role']}: {i['content']}\\n\")\n\n        now = datetime.datetime.now()\n        timestamp = now.strftime(\"%Y-%m-%d-%H-%M-%S\")\n        try:\n            # save raw messages\n            with open(file=f'C:\\code\\chatGPT\\log\\{timestamp}.txt', mode='w', encoding='utf-8') as f:\n                f.write(str(messages))\n            #save formatted messages\n            with open(file=f'C:\\code\\chatGPT\\log\\\\f-{timestamp}.txt', mode='w', encoding='utf-8') as f:\n                for i in parsed_messages:\n                    f.write(i)\n        except IOError:\n            print(\"Error: Could not create file.\")\n        print(GPT_header + 'Your file has been saved! Let me know if you need any further assistance.')\n        continue\n```\n\nNote that `split_string()` is a function I wrote solely for the purpose of readability of text. Also, `GPT_header` is a colored string achieved using `colorama`.\n\nAs for handling the `messages` part, I first initiated a list called `messages` outside of the while loop, then within the while loop, I appended both the user's prompt and ChatGPT's answer to `messages`. As for getting the responses, I followed the documentations.\n\n```python\nmessages.append({\"role\": \"user\", \"content\": user_input})\n\nresponse = openai.ChatCompletion.create(\n    model=\"gpt-3.5-turbo\",\n    messages=messages\n)\n\nprint(GPT_header + response['choices'][0]['message']['content'])\n\nmessages.append({\"role\": \"assistant\", \"content\": response['choices'][0]['message']['content']})\n```\n\nOh, and finally, as a cherry on top, I created a `.bat` file named `gpt.bat` under the `\\scripts` folder of Python, because this folder is included in `PATH` of my computer, and now I can simply type `gpt` in terminal to run my script.\n\n```bat\n@echo off\npython \"C:\\path\\to\\my\\script.py\" %*\n```\n\n## Demo\n\n![img1](https://na-406607901.imgix.net/chatgpt-cli/chatgpt-cli.png)\n\n![img2](https://na-406607901.imgix.net/chatgpt-cli/demo-1.png)\n\n![img3](https://na-406607901.imgix.net/chatgpt-cli/demo-2.png)\n\n## Conclusion\n\nThis project alone is pretty much useless, because with everything you can do on the cli program, you can do it on the official website. However, in the future, I might implement some more interesting programs, such as a foreign language tutor, a personal assistant, a story teller and so on.\n"
  },
  {
    "id": "http-server",
    "title": "HTTP Server",
    "technologies": "Python",
    "featured": false,
    "og": "https://na-406607901.imgix.net/http-server/http-server-python.png",
    "date": "2024-04-03T00:00:00.000Z",
    "body": "I built an HTTP server using Python. I followed this project on [Codecrafters](https://app.codecrafters.io), which is a great platform for implementing things on your own. Below are the specific steps taken to build a basic server.\n\n## Bind to a port\n\nWe use `socket` to spin up a server.\n\n```python\nserver_socket = socket.create_server((\"localhost\", 4221), reuse_port=True)\n\nserver_socket.accept() # wait for client\n```\n\n## Respond with 200\n\nFor any request, respond with `HTTP/1.1 200 OK\\r\\n\\r\\n`, which is the **HTTP status line**. `\\r\\n` is **CRLF**, first one is the end of the status line, second is the end of the response headers, in this case there is none.\n\n```python\nconnection, client = server_socket.accept()  # wait for client\n\nwith connection:\n    input = connection.recv(1024)\n    connection.sendall(b\"HTTP/1.1 200 OK\\r\\n\\r\\n\")\nserver_socket.close()\n```\n\n## Respond with 404\n\nNow we need to actually look at the content of the user request:\n\n```txt\nGET /index.html HTTP/1.1\nHost: localhost:4221\nUser-Agent: curl/7.64.1\n```\n\nIf the path is `/`.\n\n```python\ndef parse_input(input: bytes) -> List[str]:\n    input = input.decode()\n    return input.split(\"\\r\\n\")\n\n\ndef handle_request(input: bytes) -> bytes:\n    # we expect requests like this:\n    # GET /index.html HTTP/1.1\n    # Host: localhost:4221\n    # User-Agent: curl/7.64.1\n    input = parse_input(input)\n    method, path, version = input[0].split(\" \")\n    output = \"\"\n    if path == \"/\":\n        output = b\"HTTP/1.1 200 OK\\r\\n\\r\\n\"\n    else:\n        output = b\"HTTP/1.1 404 Not Found\\r\\n\\r\\n\"\n    return output\n```\n\n## Respond with content\n\nNow, a user request may look like:\n\n```txt\nGET /echo/abc HTTP/1.1\nHost: localhost:4221\nUser-Agent: curl/7.64.1\n```\n\nAnd our response should be:\n\n```txt\nHTTP/1.1 200 OK\nContent-Type: text/plain\nContent-Length: 3\n\nabc\n```\n\nI refactored my code for a little, and added code to handle `/echo`.\n\n```python\ndef convert_to_output(input: List[str]) -> bytes:\n    output = \"\\r\\n\".join(input) + \"\\r\\n\"\n    return output.encode()\n\n\ndef handle_request(input: bytes) -> bytes:\n    # we expect requests like this:\n    # GET /index.html HTTP/1.1\n    # Host: localhost:4221\n    # User-Agent: curl/7.64.1\n    input = parse_input(input)\n    method, path, version = input[0].split(\" \")\n    output = []\n    if path == \"/\":\n        output.append(\"HTTP/1.1 200 OK\")\n        output.append(\"\")  # empty body\n    elif len(path) >= 5 and path[:5] == \"/echo\":\n        body = path[6:]\n        output.append(\"HTTP/1.1 200 OK\")\n        output.append(\"Content-Type: text/plain\")\n        output.append(f\"Content-Length: {len(body)}\")\n        output.append(\"\")\n        output.append(body)\n    else:\n        output.append(\"HTTP/1.1 404 Not Found\")\n        output.append(\"\")\n    print(output)\n\n    return convert_to_output(output)\n```\n\n## Parse headers\n\nNow, if `/user-agent`, our response should be the `User-Agent`'s value.\n\n```txt\nGET /user-agent HTTP/1.1\nHost: localhost:4221\nUser-Agent: curl/7.64.1\n```\n\n```txt\nHTTP/1.1 200 OK\nContent-Type: text/plain\nContent-Length: 11\n\ncurl/7.64.1\n```\n\nSimply add code to handle this request:\n\n```python\nelif len(path) >= 11 and path[:11] == \"/user-agent\":\n    body = input[2].split(\": \")[1]\n    output.append(\"HTTP/1.1 200 OK\")\n    output.append(\"Content-Type: text/plain\")\n    output.append(f\"Content-Length: {len(body)}\")\n    output.append(\"\")\n    output.append(body)\n```\n\n## Concurrent connections\n\nTo handle concurrent connections, I would like to use `threading`.\n\n```python\ndef handle_client(connection):\n    with connection:\n        while True:\n            input = connection.recv(1024)\n            connection.sendall(handle_request(input))\n\n\ndef main():\n    # You can use print statements as follows for debugging, they'll be visible when running tests.\n    print(\"Logs from your program will appear here!\")\n\n    server_socket = socket.create_server((\"localhost\", 4221), reuse_port=True)\n\n    while True:\n        connection, client = server_socket.accept()  # wait for client\n        thread = threading.Thread(target=handle_client, args=(connection,))\n        thread.start()\n```\n\n## Get a file\n\nOur server should also accept an argument,\n\n```txt\n./your_server.sh --directory <directory>\n```\n\nNow, requests like `GET /files/<filename>` requires us to return the content of a file if the file is on the server within `<directory>`, the response should have a content type of `application/octet-stream`. Else return 404.\n\nI used `argparse`,\n\n```python\nparser = argparse.ArgumentParser(description=\"start the server\")\nparser.add_argument(\"--directory\", type=str)\nargs = parser.parse_args()\n```\n\n```python\nelif len(path) >= 6 and path[:6] == \"/files\":\n    file_path = os.path.join(args.directory, path[7:])\n    print(\"file path: \", file_path)\n    if os.path.isfile(file_path):\n        body = \"\"\n        with open(file_path, \"r\") as file:\n            body = file.read()\n        output.append(\"HTTP/1.1 200 OK\")\n        output.append(\"Content-Type: application/octet-stream\")\n        output.append(f\"Content-Length: {len(body)}\")\n        output.append(\"\")\n        output.append(body)\n    else:\n        print(\"file not found\")\n        output.append(\"HTTP/1.1 404 Not Found\")\n        output.append(\"Content-Length: 0\")\n        output.append(\"\")\n```\n\n## Post a file\n\nFor `POST /files/<filename>`, we need to store the request body into the specified file. Response code should be 201.\n\n```python\nelif method == \"POST\" and len(path) >= 6 and path[:6] == \"/files\":\n    file_path = os.path.join(args.directory, path[7:])\n    body = input[6]\n    with open(file_path, \"w\") as file:\n        file.write(body)\n    output.append(\"HTTP/1.1 201 OK\")\n    output.append(\"\")\n```\n\n## Conclusion\n\nNow that the server is capable of handling various `GET` requests and `POST` requests, we can say that it is actually a complete server. In this project, I got to practice parsing different parts of HTTP requests, and return specific responses. If you'd like to view my complete code, please check out my [repo](https://github.com/sonnyding1/sonnyding1-codecrafters-http-server-python), thanks!"
  },
  {
    "id": "egg-editor",
    "title": "Egg Editor",
    "technologies": "Express, React, MongoDB",
    "featured": true,
    "og": "https://na-406607901.imgix.net/egg-editor/egg-editor.png",
    "date": "2024-08-14T00:00:00.000Z",
    "body": "This project is a group project made for one of my university classes, here is the Github repo: [https://github.com/sonnyding1/CS35L-Egg](https://github.com/sonnyding1/CS35L-Egg)\n\nThe Egg Editor has the following features:\n\n- **Profile page**: Users can create their accounts using either email password or Google OAuth. They can also view file created by the user, files like by the user, and edit user name.\n- **Edit page**: Users can edit markdown files with LaTeX support. There is also a menu bar at the top of the page, which contains many useful features and shortcut keys, such as undo/redo, bold, italics, math...\n- **File management**: Users can create new files, browse existing files, delete files, and search file content. Users can also toggle file visibility between public and private.\n- **Community interaction**: Users can like and comment on other users' files. They can also view the specifics of each file.\n\n\n## Tech Stack\n\n- **Frontend**: JavaScript, React, Tailwind CSS, ShadCN UI, React-Router, React-Markdown\n- **Backend**: Node.js, Express, MongoDB, Mongoose, Passport, Swagger\n\n## Structure\n\nThe project is a monorepo, with a frontend folder and a backend folder. For the backend, I set up Express as the framework, and we decided to write RESTful API. The bulk of the backend work is populating CRUD operations with our database, in this case, MongoDB. The database contains several collections: users, files, comments. Users collection contains information about registered users. Although we have 2 methods of registering, either through email and password or through Google, each user's info is still stored in the same collection for the sake of brevity.\n\nThe frontend uses React and React-Router for creating a multi-page application. Our web app has some pages relating to the \"community\" aspect of the project, such as community page, profile page. Other pages are related to the \"editor\" aspect, they are browse page and edit page. The edit page's Markdown rendering is made possible by React Markdown.\n\nI have also set up some GitHub actions that looks for any project breaking code and linting problems. I also experimented with Swagger as the backend documentation, but later we scratched that idea due to time constraint. I do believe Swagger can be a good documentation tool though.\n\n## Auth Pain\n\nI thought log in with Google would be a nice thing to have, so I went on to integrate it into our project. Thanks to Passport.js, it was not too much of a pain, but it was still confusing. Basically, with Passport.js, OAuth 2.0 with Google becomes the following steps:\n\n1. Set up Google authentication strategy on GCP\n2. Redirect user to an endpoint handled by Passport, which prompts \"log in with Google\"\n3. After login, user gets redirected to a callback route with their user information\n4. Store the information somewhere, in session or database or somewhere else\n5. Redirect to home page\n\n## Undo Redo is Kind of Hard\n\nWhen I first tried the editor, I typed something then tried Ctrl-Z. Didn't work, because we didn't implement it. So I tried implementing it, but it seems more difficult than I thought.\n\nHow to achieve undo redo functionality? My first instinct is to use an array, record the newly typed text once in a while, and then undo removes those text, redo adds them back. Sure, this is probably going to work, but not before we answer 2 questions:\n\n1. When do we save the newly inputted string? Would it be 1 second after the user stopped typing, or would it be once every 1 second, or would it be once per word typed?\n2. What to do when an action is not simply adding text? What if the action is deletion, or bolding a piece of text?\n\nQuestion 1 probably doesn't have a correct answer, I tried to \"save\" once per 500ms and it felt alright.\n\nQuestion 2 is more tricky. If the action is deletion, then I need to record the action as \"negative that string\", which means I probably need another parameter to record if this is an add operation or delete operation. I also need another parameter to save the cursor position. I probably need even more parameters, because there are many strange cases to consider, for example, when we bold a text in Markdown it wraps the selected text with \\*\\*.\n\nImplementing undo redo in this way would probably cost too much time, so I decided to trade the complexity with space. Instead, I saved the entire Markdown content every 500ms after the user stopped typing, praying the user won't write a huge file for an extended amount of time. This method still requires some work, for example, keeping track of cursor positions, but it is certainly much easier than the first.\n\nImagine if I want to add collaboration feature just like Google Docs, that would become a nightmare.\n\n## Demo\n\n![](https://na-406607901.imgix.net/egg-editor/demo-1.png)\n![](https://na-406607901.imgix.net/egg-editor/demo-2.png)\n![](https://na-406607901.imgix.net/egg-editor/demo-3.png)\n![](https://na-406607901.imgix.net/egg-editor/demo-4.png)\n![](https://na-406607901.imgix.net/egg-editor/demo-5.png)\n![](https://na-406607901.imgix.net/egg-editor/demo-6.png)\n![](https://na-406607901.imgix.net/egg-editor/demo-7.png)\n\n## Going Forward\n\nThis has been a fun group project. There are a few more things I want to do with it though, first of them being hosting it on AWS. Right now it only runs locally. Then, I want to challenge myself and see if it is possible to create the collaboration feature on the editing page. But before that, I should probably rewrite the undo redo feature."
  },
  {
    "id": "interactive-math-web-app",
    "title": "Interative Math Web App",
    "technologies": "Next.js, React.js, MongoDB",
    "featured": true,
    "og": "https://na-406607901.imgix.net/math-webapp/math-webapp.png",
    "date": "2023-11-01T00:00:00.000Z",
    "body": "Link to the project so you could try yourself: [https://basic-math-livid.vercel.app/](https://basic-math-livid.vercel.app/)\n\nMy interactive math web app has the following features:\n\n*   Generates math exercises (addition, multiplication, factorization) with difficulty selectors\n    \n*   Experience and level system\n    \n*   Account system so users can retain their levels\n    \n\n## Tech Stack\n\nThis project is a full-stack project, and I mainly used Next.js. For the UI, I used Tailwind CSS and ShadCN UI. For the login functionality, instead of implementing login and auth functionalities on my own, I used a third-party service called [Clerk](https://clerk.com/). I did use MongoDB for storing users' information such as the number of problems solved, experience, and so on. To interact with MongoDB, I used an ORM called Prisma.\n\n## Structure\n\nFor each problem page (Addition, Multiplication, Factorization), there is a corresponding API endpoint that is in charge of generating math problems and validating user answers.\n\nAs for the user's experience points, levels, and number of problems solved, we make requests to an API endpoint in the backend, which then makes requests to MongoDB. We have to consider two different situations: when the user is logged in and when the user is not logged in. If the user is not logged in, then we return initial values like `level: 1, problems_solved: 0`. If the user is logged in, then we fetch data from the database. To ensure low latency and that the level and experience data is accessible everywhere, I also store variables in [Zustand](https://github.com/pmndrs/zustand).\n\n![](https://na-406607901.imgix.net/math-webapp/structure.png)\n\n## Rendering LaTeX\n\nI used MathJax for rendering math equations into LaTeX forms. Specifically, I included the MathJax script in the root-level `layout.tsx`, so now every math block may be rendered as a LaTeX math block:\n\n```tsx\n<head>\n  <Script id=\"MathJax-script\" async src=\"https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js\" />\n</head>\n```\n\n## Unexpected pain: math input field\n\nNow that I have a system that can generate random math problems, I need to work on the input field. If the problem itself is rendered using LaTeX, I would also like the user input field to render LaTeX as well.\n\nBut how to accomplish this functionality? I tried to create a preview area, using MathJax to re-render the preview area every time the user inputs new characters, but it was not possible. I attempted this:\n\n```tsx\nconst typeset = (selector: () => HTMLElement) => {\n  const mathJax = (window as any).MathJax;\n  // If MathJax script hasn't been loaded yet, then do nothing.\n  if (!mathJax) {\n      return null;\n  }\n  mathJax.startup.promise = mathJax.startup.promise\n      .then(() => {\n      selector();\n      return mathJax.typesetPromise();\n      })\n      .catch((err: any) => console.error(`Typeset failed: ${err.message}`));\n  return mathJax.startup.promise;\n};\n\nconst ref = React.createRef<HTMLSpanElement>();\nuseEffect(() => {\n    typeset(() => ref.current!);\n}, [problem, answer]);\n```\n\nBut it was not successful. Then, I tried searching for existing packages that would make good math input fields, and I found [MathLive](https://www.npmjs.com/package/mathlive), just what I needed. I was able to use it by attaching a `Script`, and then use it as such:\n\n```tsx\n<math-field\n  id='answer'\n  onInput={(e: React.ChangeEvent<HTMLInputElement> ) => {\n    setUserAnswer(e.target.value);\n  }}\n>\n  {userAnswer}\n</math-field>\n```\n\n## Demo\n\n![](https://na-406607901.imgix.net/math-webapp/math-web-app-demo.png)\n\n## Going forward\n\nThere are a ton of features that I want to add to this web app. First of all, I can easily add a set of new problems, like solving Trigonometry problems, integration, differentiation... Then, I could also introduce a new mode that generates problem sets and allow PDF export for students to practice on paper. I could also try to make use of the leveling system, such that as users' levels become higher, they can get new themes and new problem sets unlocked. I could rewrite my login and auth system. I could also add a landing page, or refactor my code... Anyways, I am actually very happy with what I've built, and I'd love to devote more time to this project and make it better."
  }
]