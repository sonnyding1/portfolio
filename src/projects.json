[
  {
    "id": "japanese-conversation-bot",
    "title": "Japanese Conversation Bot",
    "technologies": "Django, JavaScript, Docker",
    "featured": true,
    "og": "https://na-406607901.imgix.net/japanese-conversation-bot/japanese-conversation-bot.png",
    "date": "2023-04-01T00:00:00.000Z",
    "body": "This is a project that I worked on when OpenAI API first became publicly available. The aim of the project is to have a Japanese tutor who can converse with the user in Japanese, correct the user's errors, and encourage the user to become more proficient in speaking Japanese as they converse with the chatbot.\n\n## Overview\n\nThe ideal flow of the project is: user presses the \"speak\" button and speaks in Japanese -> Whisper transcribes text, transcribed text appears in the text area, users may manually correct any mistakes by typing -> submit user message -> user message sent to OpenAI API, the API returns a response -> response as a piece of text is displayed on the web app -> response as a piece of text is sent to VoiceVox, which performs text to speech.\n\n![](https://na-406607901.imgix.net/japanese-conversation-bot/flowchart.png)\n\nThis project uses Flask and HTML, Tailwind CSS, JavaScript.\n\n## Capture User Audio\n\nA `POST` request is sent from my web app's root route to `/transcribe`. In there, I captured a blob of audio, saved it, and sent it to Whisper via `openai`, a Python wrapper of the OpenAI API.\n\n```python\nblob = request.files['blob'].read()\nwith open('blob.wav', 'wb') as f:\n    f.write(blob)\naudio_file = open('blob.wav', \"rb\")\nopenai.api_key = config.OPENAI_API_KEY\ntranscript = openai.Audio.transcribe(\"whisper-1\", audio_file)[\"text\"]\nreturn jsonify({'output': transcript})\n```\n\n## Choosing good Text to Speech API\n\nI have actually compared different TTS options available to me.\n\nSpeechCloud API was too expensive, it was priced at around 0.01 Euro per word/character. Coqui seems doable, but currently stuck with some character parsing issues. Voicevox proves to be very useful. I downloaded it locally, which also started a local at the same time. I wrote a script that performs audio query and synthesizes the query into an audio file. I was also able to parse the returned JSON from get_speakers() method to have a clearer manual on speaker selection.\n\n## VoiceVox in Docker\n\nAt the beginning, I made use of VoiceVox by actually downloading the software and opening it locally. To make it simpler for the user, I used the following code snippet to run a Docker container version of the VoiceVox server.\n\n```python\nimport docker\n\nclient = docker.from_env()\n\n# Pull the Docker image\nclient.images.pull('voicevox/voicevox_engine:cpu-ubuntu20.04-latest')\n\n# Run the Docker container\ncontainer = client.containers.run(\n    'voicevox/voicevox_engine:cpu-ubuntu20.04-latest',\n    detach=True,\n    ports={'50021/tcp': ('127.0.0.1', 50021)},\n    remove=True,\n    tty=True\n)\n\n# Print the container logs\nprint(container.logs(follow=True))\n```\n\nAlso, stop the Docker container that contains the VoiceVox image on exit using the atexit library.\n\n```python\ndef OnExitApp():\n    tts.stop_voicevox()\n\natexit.register(OnExitApp)\n```\n\n## UI\n\nThe UI looks like this:\n\n![](https://na-406607901.imgix.net/japanese-conversation-bot/japanese-conversation-bot.png)\n\nBefore that, I have also made a prototype using Gradio.\n\n![](https://na-406607901.imgix.net/japanese-conversation-bot/gradio.png)\n\n## Closing Notes\n\nGoing further, I may be able to improve the UI, incorporate more features such as displaying Furigana, bookmarking good conversations, and so on. Overall, it was very fun working on this project. I got to practice a lot about how to leverage existing solutions to build something that I wish existed.\n"
  },
  {
    "id": "chatgpt-cli",
    "title": "ChatGPT cli",
    "technologies": "Python",
    "featured": false,
    "og": "https://na-406607901.imgix.net/chatgpt-cli/chatgpt-cli.png",
    "date": "2023-03-01T00:00:00.000Z",
    "body": "Recently, OpenAI released API for ChatGPT, I took advantage of that, and did a little test run. This is going to be a fairly short blog post, all I've done is to test the new API.\n\n## API\n\nAccording to [OpenAI's API](https://platform.openai.com/docs/guides/chat/introduction), a call for a ChatGPT response using Python is in the following format:\n\n```python\nimport openai\n\nopenai.ChatCompletion.create(\n  model=\"gpt-3.5-turbo\",\n  messages=[\n        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n        {\"role\": \"user\", \"content\": \"Who won the world series in 2020?\"},\n        {\"role\": \"assistant\", \"content\": \"The Los Angeles Dodgers won the World Series in 2020.\"},\n        {\"role\": \"user\", \"content\": \"Where was it played?\"}\n    ]\n)\n```\n\nHere, `gpt-3.5-turbo` is ChatGPT. `messages` stores the whole conversation, including the initial prompt in the role of `system`, user's questions in the role of `user`, and ChatGPT's response in the role of `assistant`. The `create` function returns a response like this:\n\n```txt\n{\n 'id': 'chatcmpl-6p9XYPYSTTRi0xEviKjjilqrWU2Ve',\n 'object': 'chat.completion',\n 'created': 1677649420,\n 'model': 'gpt-3.5-turbo',\n 'usage': {'prompt_tokens': 56, 'completion_tokens': 31, 'total_tokens': 87},\n 'choices': [\n   {\n    'message': {\n      'role': 'assistant',\n      'content': 'The 2020 World Series was played in Arlington, Texas at the Globe Life Field, which was the new home stadium for the Texas Rangers.'},\n    'finish_reason': 'stop',\n    'index': 0\n   }\n  ]\n}\n```\n\nWhich, we really only care about the content most of the time.\n\n## Implementation\n\nFirst of all, I get my OpenAI API key. Then, I simply wrote a while loop, at the beginning of each iteration it asks for a user input. If user types !Q, then the program quits. If user types !SAVE, program saves this session's entire conversation for record or for future use. I have both raw version and formatted version.\n\n```python\nwhile True:\n    user_input = input(user_header)\n    # exit condition\n    if user_input == \"!Q\":\n        return\n    # promp save\n    if user_input == \"!SAVE\":\n        parsed_messages = []\n        for i in messages:\n            parsed_messages.append(f\"{i['role']}: {i['content']}\\n\")\n\n        now = datetime.datetime.now()\n        timestamp = now.strftime(\"%Y-%m-%d-%H-%M-%S\")\n        try:\n            # save raw messages\n            with open(file=f'C:\\code\\chatGPT\\log\\{timestamp}.txt', mode='w', encoding='utf-8') as f:\n                f.write(str(messages))\n            #save formatted messages\n            with open(file=f'C:\\code\\chatGPT\\log\\\\f-{timestamp}.txt', mode='w', encoding='utf-8') as f:\n                for i in parsed_messages:\n                    f.write(i)\n        except IOError:\n            print(\"Error: Could not create file.\")\n        print(GPT_header + 'Your file has been saved! Let me know if you need any further assistance.')\n        continue\n```\n\nNote that `split_string()` is a function I wrote solely for the purpose of readability of text. Also, `GPT_header` is a colored string achieved using `colorama`.\n\nAs for handling the `messages` part, I first initiated a list called `messages` outside of the while loop, then within the while loop, I appended both the user's prompt and ChatGPT's answer to `messages`. As for getting the responses, I followed the documentations.\n\n```python\nmessages.append({\"role\": \"user\", \"content\": user_input})\n\nresponse = openai.ChatCompletion.create(\n    model=\"gpt-3.5-turbo\",\n    messages=messages\n)\n\nprint(GPT_header + response['choices'][0]['message']['content'])\n\nmessages.append({\"role\": \"assistant\", \"content\": response['choices'][0]['message']['content']})\n```\n\nOh, and finally, as a cherry on top, I created a `.bat` file named `gpt.bat` under the `\\scripts` folder of Python, because this folder is included in `PATH` of my computer, and now I can simply type `gpt` in terminal to run my script.\n\n```bat\n@echo off\npython \"C:\\path\\to\\my\\script.py\" %*\n```\n\n## Demo\n\n![img1](https://na-406607901.imgix.net/chatgpt-cli/chatgpt-cli.png)\n\n![img2](https://na-406607901.imgix.net/chatgpt-cli/demo-1.png)\n\n![img3](https://na-406607901.imgix.net/chatgpt-cli/demo-2.png)\n\n## Conclusion\n\nThis project alone is pretty much useless, because with everything you can do on the cli program, you can do it on the official website. However, in the future, I might implement some more interesting programs, such as a foreign language tutor, a personal assistant, a story teller and so on.\n"
  },
  {
    "id": "http-server",
    "title": "HTTP Server",
    "technologies": "Python",
    "featured": false,
    "og": "https://na-406607901.imgix.net/http-server/http-server-python.png",
    "date": "2024-04-03T00:00:00.000Z",
    "body": "I built an HTTP server using Python. I followed this project on [Codecrafters](https://app.codecrafters.io), which is a great platform for implementing things on your own. Below are the specific steps taken to build a basic server.\n\n## Bind to a port\n\nWe use `socket` to spin up a server.\n\n```python\nserver_socket = socket.create_server((\"localhost\", 4221), reuse_port=True)\n\nserver_socket.accept() # wait for client\n```\n\n## Respond with 200\n\nFor any request, respond with `HTTP/1.1 200 OK\\r\\n\\r\\n`, which is the **HTTP status line**. `\\r\\n` is **CRLF**, first one is the end of the status line, second is the end of the response headers, in this case there is none.\n\n```python\nconnection, client = server_socket.accept()  # wait for client\n\nwith connection:\n    input = connection.recv(1024)\n    connection.sendall(b\"HTTP/1.1 200 OK\\r\\n\\r\\n\")\nserver_socket.close()\n```\n\n## Respond with 404\n\nNow we need to actually look at the content of the user request:\n\n```txt\nGET /index.html HTTP/1.1\nHost: localhost:4221\nUser-Agent: curl/7.64.1\n```\n\nIf the path is `/`.\n\n```python\ndef parse_input(input: bytes) -> List[str]:\n    input = input.decode()\n    return input.split(\"\\r\\n\")\n\n\ndef handle_request(input: bytes) -> bytes:\n    # we expect requests like this:\n    # GET /index.html HTTP/1.1\n    # Host: localhost:4221\n    # User-Agent: curl/7.64.1\n    input = parse_input(input)\n    method, path, version = input[0].split(\" \")\n    output = \"\"\n    if path == \"/\":\n        output = b\"HTTP/1.1 200 OK\\r\\n\\r\\n\"\n    else:\n        output = b\"HTTP/1.1 404 Not Found\\r\\n\\r\\n\"\n    return output\n```\n\n## Respond with content\n\nNow, a user request may look like:\n\n```txt\nGET /echo/abc HTTP/1.1\nHost: localhost:4221\nUser-Agent: curl/7.64.1\n```\n\nAnd our response should be:\n\n```txt\nHTTP/1.1 200 OK\nContent-Type: text/plain\nContent-Length: 3\n\nabc\n```\n\nI refactored my code for a little, and added code to handle `/echo`.\n\n```python\ndef convert_to_output(input: List[str]) -> bytes:\n    output = \"\\r\\n\".join(input) + \"\\r\\n\"\n    return output.encode()\n\n\ndef handle_request(input: bytes) -> bytes:\n    # we expect requests like this:\n    # GET /index.html HTTP/1.1\n    # Host: localhost:4221\n    # User-Agent: curl/7.64.1\n    input = parse_input(input)\n    method, path, version = input[0].split(\" \")\n    output = []\n    if path == \"/\":\n        output.append(\"HTTP/1.1 200 OK\")\n        output.append(\"\")  # empty body\n    elif len(path) >= 5 and path[:5] == \"/echo\":\n        body = path[6:]\n        output.append(\"HTTP/1.1 200 OK\")\n        output.append(\"Content-Type: text/plain\")\n        output.append(f\"Content-Length: {len(body)}\")\n        output.append(\"\")\n        output.append(body)\n    else:\n        output.append(\"HTTP/1.1 404 Not Found\")\n        output.append(\"\")\n    print(output)\n\n    return convert_to_output(output)\n```\n\n## Parse headers\n\nNow, if `/user-agent`, our response should be the `User-Agent`'s value.\n\n```txt\nGET /user-agent HTTP/1.1\nHost: localhost:4221\nUser-Agent: curl/7.64.1\n```\n\n```txt\nHTTP/1.1 200 OK\nContent-Type: text/plain\nContent-Length: 11\n\ncurl/7.64.1\n```\n\nSimply add code to handle this request:\n\n```python\nelif len(path) >= 11 and path[:11] == \"/user-agent\":\n    body = input[2].split(\": \")[1]\n    output.append(\"HTTP/1.1 200 OK\")\n    output.append(\"Content-Type: text/plain\")\n    output.append(f\"Content-Length: {len(body)}\")\n    output.append(\"\")\n    output.append(body)\n```\n\n## Concurrent connections\n\nTo handle concurrent connections, I would like to use `threading`.\n\n```python\ndef handle_client(connection):\n    with connection:\n        while True:\n            input = connection.recv(1024)\n            connection.sendall(handle_request(input))\n\n\ndef main():\n    # You can use print statements as follows for debugging, they'll be visible when running tests.\n    print(\"Logs from your program will appear here!\")\n\n    server_socket = socket.create_server((\"localhost\", 4221), reuse_port=True)\n\n    while True:\n        connection, client = server_socket.accept()  # wait for client\n        thread = threading.Thread(target=handle_client, args=(connection,))\n        thread.start()\n```\n\n## Get a file\n\nOur server should also accept an argument,\n\n```txt\n./your_server.sh --directory <directory>\n```\n\nNow, requests like `GET /files/<filename>` requires us to return the content of a file if the file is on the server within `<directory>`, the response should have a content type of `application/octet-stream`. Else return 404.\n\nI used `argparse`,\n\n```python\nparser = argparse.ArgumentParser(description=\"start the server\")\nparser.add_argument(\"--directory\", type=str)\nargs = parser.parse_args()\n```\n\n```python\nelif len(path) >= 6 and path[:6] == \"/files\":\n    file_path = os.path.join(args.directory, path[7:])\n    print(\"file path: \", file_path)\n    if os.path.isfile(file_path):\n        body = \"\"\n        with open(file_path, \"r\") as file:\n            body = file.read()\n        output.append(\"HTTP/1.1 200 OK\")\n        output.append(\"Content-Type: application/octet-stream\")\n        output.append(f\"Content-Length: {len(body)}\")\n        output.append(\"\")\n        output.append(body)\n    else:\n        print(\"file not found\")\n        output.append(\"HTTP/1.1 404 Not Found\")\n        output.append(\"Content-Length: 0\")\n        output.append(\"\")\n```\n\n## Post a file\n\nFor `POST /files/<filename>`, we need to store the request body into the specified file. Response code should be 201.\n\n```python\nelif method == \"POST\" and len(path) >= 6 and path[:6] == \"/files\":\n    file_path = os.path.join(args.directory, path[7:])\n    body = input[6]\n    with open(file_path, \"w\") as file:\n        file.write(body)\n    output.append(\"HTTP/1.1 201 OK\")\n    output.append(\"\")\n```\n\n## Conclusion\n\nNow that the server is capable of handling various `GET` requests and `POST` requests, we can say that it is actually a complete server. In this project, I got to practice parsing different parts of HTTP requests, and return specific responses. If you'd like to view my complete code, please check out my [repo](https://github.com/sonnyding1/sonnyding1-codecrafters-http-server-python), thanks!"
  },
  {
    "id": "interactive-math-web-app",
    "title": "Interative Math Web App",
    "technologies": "Next.js, React.js, MongoDB",
    "featured": true,
    "og": "https://na-406607901.imgix.net/math-webapp/math-webapp.png",
    "date": "2023-11-01T00:00:00.000Z",
    "body": "My interactive math web app has the following features:\n\n- Generates math exercises (addition, multiplication, factorization) with difficulty selectors\n    \n- Experience and level system\n    \n- Account system so users can retain their levels\n    \n\n## Tech Stack\n\nThis project is a fullstack project, I mainly used Next.js. For the UI, I used Tailwind CSS and ShadCN UI. For the login functionality, instead of implementing login and auth functionalities on my own, I used a third party service called [Clerk](https://clerk.com/). I did use MongoDB for storing users' information such as number of problems solved, experience, and so on. To interact with MongoDB, I used an ORM called Prisma.\n\n## Structure\n\nFor each problem page (Addition, Multiplication, Factorization), there is a corresponding API endpoint which is in charge of generating math problems, validating user answers.\n\nAs for the user's experience points, levels, and number of problems solved, we make request to an API endpoint in the backend, which then makes request to MongoDB. We have to consider 2 different situations: when the user is logged in and when the user is not logged in. If the user is not logged in, then return initial values like `level: 1, problems_solved: 0`. If the user is logged in, then fetch data from database. To ensure low latency and that the level and experience data is accessible everywhere, I also store variables in [Zustand](https://github.com/pmndrs/zustand).\n\n![](https://na-406607901.imgix.net/math-webapp/structure.png)\n\n## Rendering LaTeX\n\nI used MathJax for rendering math equations into LaTeX forms. Specifically, I included MathJax script in root level `layout.tsx`, so now every math block may be rendered as LaTeX math block:\n\n```tsx\n<head>\n  <Script id=\"MathJax-script\" async src=\"https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js\" />\n</head>\n```\n\n## Unexpected pain: math input field\n\nNow that I have a system that can generate random math problems, I need to work on the input field. If the problem itself is rendered using LaTeX, of course I would also like the user input field to render LaTeX as well.\n\nBut how to accomplish this functionality? I tried to create a preview area, using MathJax to re-render the preview area every time user inputs new characters, but it was not possible. I attempted this:\n\n```tsx\nconst typeset = (selector: () => HTMLElement) => {\n  const mathJax = (window as any).MathJax;\n  // If MathJax script hasn't been loaded yet, then do nothing.\n  if (!mathJax) {\n      return null;\n  }\n  mathJax.startup.promise = mathJax.startup.promise\n      .then(() => {\n      selector();\n      return mathJax.typesetPromise();\n      })\n      .catch((err: any) => console.error(`Typeset failed: ${err.message}`));\n  return mathJax.startup.promise;\n};\n\nconst ref = React.createRef<HTMLSpanElement>();\nuseEffect(() => {\n    typeset(() => ref.current!);\n}, [problem, answer]);\n```\n\nBut it was not successful. Then, I tried searching for existing packages that would make good math input fields, and I found [MathLive](https://www.npmjs.com/package/mathlive), just what I needed. I was able to use it by attaching a `Script`, and then use it as such:\n\n```tsx\n<math-field\n  id='answer'\n  onInput={(e: React.ChangeEvent<HTMLInputElement> ) => {\n    setUserAnswer(e.target.value);\n  }}\n>\n  {userAnswer}\n</math-field>\n```\n\n## Demo\n\n![](https://na-406607901.imgix.net/math-webapp/math-web-app-demo.png)\n\n## Going forward\n\nThere are a ton of features that I want to add to this web app. First of all, I can easily add a set of new problems, like solving Trigonometry problems, integration, differentiation... Then, I could also introduce a new mode that generates problem sets, and allow PDF export for students to practice on paper. I could also try to make use of the leveling system, such that as users' level become higher, they can get new themes and new problem sets unlocked. I could rewrite my login and auth system. I could also add a landing page, or refactor my code... Anyways, I am acutally very happy with what I've built, and I'd love to devote more time to this project and make it better."
  }
]